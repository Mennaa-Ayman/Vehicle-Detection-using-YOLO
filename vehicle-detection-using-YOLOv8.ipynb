{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7659344,"sourceType":"datasetVersion","datasetId":4465725}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics","metadata":{"trusted":true,"_kg_hide-output":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib as plt\nimport torch \nimport cv2, random, os\nimport torch.nn as nn\nfrom torchvision import models, datasets, transforms\nfrom torchvision.datasets import GTSRB\nfrom torch.utils.data import random_split\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Loading Data","metadata":{}},{"cell_type":"code","source":"data_dir = \"/kaggle/input/vehicledetection/VehiclesDetectionDataset\"\ntrain_dir = os.path.join(data_dir, \"Train\")\ntest_dir = os.path.join(data_dir, \"Test/images\")\nvalid_dir = os.path.join(data_dir, \"Train\")\nyaml_dir = \"/kaggle/input/vehicledetection/VehiclesDetectionDataset/dataset.yaml\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training YOLO on the vehicles dataset","metadata":{}},{"cell_type":"code","source":"from ultralytics import YOLO\nmodel = YOLO(\"yolov8s.pt\")\n\ntrain_results = model.train(\n    data=yaml_dir,  \n    epochs=10,  \n    imgsz=640,  \n    device=\"cpu\", \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluate the model's performance on the validation set\n","metadata":{}},{"cell_type":"code","source":"metrics = model.val()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results = model.val(\n    data=yaml_dir,\n    split='test',     # evaluate on test split\n    imgsz=640,\n    conf=0.25\n)\n\n# Print metrics summary\nprint(\"Precision:\", results.box.map50)\nprint(\"mAP@50:\", results.box.map50)\nprint(\"mAP@50-95:\", results.box.map)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Perform object detection on an image","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2, random, os\n\n# Path to test images\ntest_path = \"/kaggle/input/vehicledetection/VehiclesDetectionDataset/test/images\"\n\nimage_files = [f for f in os.listdir(test_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\nsample_imgs = random.sample(image_files, 8)\n\nplt.figure(figsize=(20, 10))\n\nfor i, f in enumerate(sample_imgs):\n    img_path = os.path.join(test_path, f)\n    results = model.predict(source=img_path, conf=0.25, verbose=False)\n    pred_img = results[0].plot()\n    pred_img = cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB)\n\n    plt.subplot(2, 4, i + 1)\n    plt.imshow(pred_img)\n    plt.title(f)\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"scrolled":true},"outputs":[],"execution_count":null}]}